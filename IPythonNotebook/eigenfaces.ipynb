{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as pyplot\n",
    "\n",
    "from numpy.random import RandomState\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "\n",
    "dataset = fetch_olivetti_faces(shuffle = True, random_state = RandomState(127))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and condition dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faces: (400, 4096)\n"
     ]
    }
   ],
   "source": [
    "faces = dataset.data\n",
    "\n",
    "print('faces: %s' % str(faces.shape)) # |samples| x |features|\n",
    "\n",
    "# global centering\n",
    "faces_mean = faces.mean(axis = 0)\n",
    "faces_centered = faces - faces_mean\n",
    "\n",
    "# local centering\n",
    "faces_centered -= faces_centered.mean(axis = 1).reshape(faces.shape[0], -1)\n",
    "\n",
    "faces_centered.shape # |samples| x |features|\n",
    "\n",
    "split = int(0.25*len(faces))\n",
    "\n",
    "test_faces = faces_centered[:split]\n",
    "test_targets = dataset.target[:split]\n",
    "\n",
    "train_faces = faces_centered[split:]\n",
    "train_targets = dataset.target[split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Eigen Analysis\n",
    "\n",
    "\"The eigenvectors are derived from the covariance matrix of the probability distribution over the high-dimensional vector space of face images. The eigenfaces themselves form a basis set of all images used to construct the covariance matrix. This produces dimension reduction by allowing the smaller set of basis images to represent the original training images. Classification can be achieved by comparing how faces are represented by the basis set.\" __- Wikipedia__\n",
    "\n",
    "In other words, PCA is a linear transformation of data to a new coordinate system. Converting large data sets to a coordinate system has many advantages and applications for computer vision. Large images can be represented as smaller vectors which is why PCA is a technique in auto-encoding.\n",
    "\n",
    "We can match one face with another by projecting a face into the manifold and comparing the distance to a traning face projected into the manifold.\n",
    "\n",
    "Since Euclidean distance is N dimensional, we can use this as our cost function. We can also rank the traning set face in order of how closely they match the test face.\n",
    "\n",
    "## The Procedure\n",
    "1. Load a training set of faces\n",
    "    * compute the mean of these faces\n",
    "    * compute the centered set of faces\n",
    "2. Compute the covariance matrix using the centred set of faces\n",
    "3. Compute the eigenvectors fo the covariance matrix using Singular Value Decomposition (SVD)\n",
    "\n",
    "## The Speed-up\n",
    "The procedure can become computationally intensive if the wrong approach is taken when generating the covariance matrix of the set of centred faces. Consider that the number of features (pixels) will likely be much larget than the number of samples (faces).\n",
    "\n",
    "* Let $A$ be the set of centred faces, samples by features\n",
    "* Let $C$ be the covariance matrix of $A$, such that $C = A \\cdot A^T$\n",
    "* Let $L$ be the surrogate of matrix $C$, such that $L = A^T \\cdot A$\n",
    "\n",
    "Matrix $C$ will yeild a size of __features by features__\n",
    "\n",
    "Matrix $L$ will yeild a size of __samples by samples__\n",
    "\n",
    "Calculating $C$ directly is computationally expensive since the number of features is significantly larger than then number of samples. There is however a faster way which will be explained below.\n",
    "\n",
    "\n",
    "## The Math\n",
    "* Let $v_C$ be the set of eigenvectors of matrix $C$\n",
    "* Let $\\lambda_C$ be the set of eigenvalues of matrix $C$\n",
    "* Let $v_L$ be the set of eigenvectors of matrix $L$\n",
    "* Let $\\lambda_L$ be the set of eigenvalues of matrix $L$\n",
    "\n",
    "__Proof__\n",
    "\n",
    "Consider the eigenvector $v_L$ of $L = A^T \\cdot A$ such that,\n",
    "\n",
    "$L \\cdot v_L = \\lambda_L \\cdot v_L$\n",
    "\n",
    "$(A^T \\cdot A) \\cdot v_L = \\lambda_L \\cdot v_L$\n",
    "\n",
    "Premultiplying both sides by $A$, produces,\n",
    "\n",
    "$A \\cdot (A^T \\cdot A \\cdot v_L) = A \\cdot (\\lambda_L \\cdot v_L)$\n",
    "\n",
    "$(A \\cdot A^T) \\cdot A \\cdot v_L = A \\cdot (\\lambda_L \\cdot v_L)$\n",
    "\n",
    "$C \\cdot (A \\cdot v_L) = \\lambda_L \\cdot (A \\cdot v_L)$\n",
    "\n",
    "Therefore,\n",
    "* $A \\cdot v_L$ is an eigenvector of $C$, and,\n",
    "* $\\lambda_C$ is an eigenvalue of $C$\n",
    "\n",
    "Therefore,\n",
    "* $v_C = A \\cdot v_L$\n",
    "* $\\lambda_C = \\lambda_L$\n",
    "\n",
    "This concludes that $v_C = A \\cdot v_L$, which is very inexpensive to compute since the number of samples is significantly smaller than features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute surrogate covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: (300, 4096)\n",
      "L: (300, 300)\n"
     ]
    }
   ],
   "source": [
    "A = train_faces\n",
    "print('A: %s' % str(A.shape)) # |samples\\ x |features|\n",
    "L = A.dot(A.T)\n",
    "print('L: %s' % str(L.shape)) # |samples| x |samples|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute strong eigen vectors\n",
    "We can auto-encode at this step by discarding any eigenvectors which are not strong basis vectors, ie they are nearly parallel to another basis. This is a compression technique that sacrifices accuracy for efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L eigenvectors: (300, 296)\n"
     ]
    }
   ],
   "source": [
    "(L_eigenvalues, L_eigenvectors) = numpy.linalg.eig(L)\n",
    "L_eigenvectors_strong = L_eigenvectors[:,numpy.array([True if (x > 1) else False for x in L_eigenvalues])]\n",
    "print('L eigenvectors: %s' % str(L_eigenvectors_strong.shape)) # |samples| x |strong samples|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute eigenfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenfaces: (296, 4096)\n"
     ]
    }
   ],
   "source": [
    "C_eigenvectors = A.T.dot(L_eigenvectors_strong).T # eigenfaces\n",
    "eigenfaces = C_eigenvectors\n",
    "print('eigenfaces: %s' % str(eigenfaces.shape)) # |samples| x |features|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project faces into eigenface space\n",
    "This is the last step of training our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 296)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Project all training data into eigenface space\n",
    "train_faces_projected = numpy.vstack([eigenfaces.dot(train_face) for train_face in train_faces])\n",
    "train_faces_projected.shape # |samples| x |strong samples|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform test on faces outside our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76% accuracy\n",
      "... amongst 40 unique people\n"
     ]
    }
   ],
   "source": [
    "# Match test faces with training\n",
    "\n",
    "correct = 0.0\n",
    "trails = len(test_faces)\n",
    "\n",
    "for test_index in range(trails):\n",
    "    \n",
    "    test_face = test_faces[test_index]\n",
    "    test_target = test_targets[test_index]\n",
    "    \n",
    "    test_face_projected = eigenfaces.dot(test_face) # Note: faces are already normalized\n",
    "    \n",
    "    distances = numpy.array([((test_face_projected - train_face_projected)**2).sum() for train_face_projected in train_faces_projected])\n",
    "    \n",
    "    guess_index = distances.argmin()\n",
    "    guess_face = train_faces[guess_index]\n",
    "    guess_target = train_targets[guess_index]\n",
    "    \n",
    "    is_correct = (test_target == guess_target)\n",
    "    \n",
    "    if (is_correct):\n",
    "        correct += 1.0\n",
    "    \n",
    "    # Show some examples of matching...\n",
    "    if (test_index < 10):\n",
    "        # Test face...\n",
    "        pyplot.subplot(1,2,1)\n",
    "        pyplot.title('Test face')\n",
    "        pyplot.imshow(\n",
    "            test_face.reshape([64, 64]),\n",
    "            cmap = pyplot.cm.gray,\n",
    "            interpolation = 'nearest'\n",
    "        )\n",
    "        # Guess face...\n",
    "        pyplot.subplot(1,2,2)\n",
    "        pyplot.title('Guess face [%s match]' % ('Correct' if is_correct else 'Incorrect'))\n",
    "        pyplot.imshow(\n",
    "            guess_face.reshape([64, 64]),\n",
    "            cmap = pyplot.cm.gray,\n",
    "            interpolation = 'nearest'\n",
    "        )\n",
    "        # Show...\n",
    "        pyplot.show()\n",
    "\n",
    "print '%d%% accuracy' % int(100.0*correct/trails)\n",
    "print '... amongst %d unique people' % int(len(frozenset(dataset.target)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
